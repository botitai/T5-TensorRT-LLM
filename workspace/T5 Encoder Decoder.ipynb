{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd85987d-77b9-4115-bc19-6810efc1a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tritonclient.grpc as grpcclient\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4454983-41b8-4dad-8161-ff8f548f665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRITON_SERVER_URL = os.getenv(\"TRITON_SERVER_URL\", \"0.0.0.0\")\n",
    "URL = f\"{TRITON_SERVER_URL}:8001\"\n",
    "CLIENT = grpcclient.InferenceServerClient(url=URL, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ecab2e-4c3b-48b8-b89a-3654b99a842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_t5_request(client, input_texts: List[str], max_new_tokens: List[int], num_beams: List[int]):\n",
    "\n",
    "    assert len(input_texts) == len(max_new_tokens) == len(num_beams), \"All inputs must have same batch size!\"\n",
    "    \n",
    "    input_texts = np.array(input_texts, dtype=\"object\")\n",
    "    max_new_tokens = np.array(max_new_tokens)\n",
    "    num_beams = np.array(num_beams)\n",
    "    inputs = [\n",
    "        grpcclient.InferInput(\"input_text\", input_texts.shape, \"BYTES\"),\n",
    "        grpcclient.InferInput(\"max_new_tokens\", max_new_tokens.shape, \"INT64\"),\n",
    "        grpcclient.InferInput(\"num_beams\", num_beams.shape, \"INT64\")\n",
    "    ]    \n",
    "    inputs[0].set_data_from_numpy(input_texts)\n",
    "    inputs[1].set_data_from_numpy(max_new_tokens)\n",
    "    inputs[2].set_data_from_numpy(num_beams)\n",
    "\n",
    "    triton_outputs = [grpcclient.InferRequestedOutput(\"output_text\")]\n",
    "\n",
    "    infer_result = client.infer(\n",
    "        \"t5\",\n",
    "        inputs,\n",
    "        model_version=\"1\",\n",
    "        outputs=triton_outputs   \n",
    "        )\n",
    "\n",
    "    return infer_result.as_numpy(\"output_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d22bf19-9610-4210-a5bd-ca8b3c8310b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'Bonjour!', b'Hallo!'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = [[\"Translate English to French: Hello!\"], [\"Translate English to German: Hello!\"]]\n",
    "max_new_tokens = [[64], [64]]\n",
    "num_beams = [[1], [1]]\n",
    "\n",
    "send_t5_request(CLIENT, input_texts, max_new_tokens, num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4b680-dd1c-47ac-aa87-d83e6fd7b5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
